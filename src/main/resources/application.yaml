# 性能基准测试配置示例
evalscope:
  models:
    # 基准模型对照
    benchmark-model-1:
      type: "chat"
      provider: "mock"
      enabled: true
      parameters:
        endpoint: "mock://localhost:8080"
        max_tokens: 500
        temperature: 0.1
        response_delay_ms: 150  # 基准延迟
        response_variation_ms: 50  # ±50ms变化
        success_rate: 0.97  # 97%成功率

    # 高性能优化模型
    fast-model:
      type: "chat"
      provider: "mock"
      enabled: true
      parameters:
        endpoint: "mock://localhost:8081"
        max_tokens: 500
        temperature: 0.1
        response_delay_ms: 80  # 更快响应
        response_variation_ms: 20  # 更小变化
        success_rate: 0.99  # 更高成功率

  evaluations:
    # 标准性能基准测试
    standard_benchmark:
      models: ["benchmark-model-1"]
      evaluators: ["chat"]
      maxConcurrency: 1
      saveResults: true
      outputPath: "results/benchmark"
      parameters:
        max_examples: 100
        timeout_seconds: 20
        warmup_iterations: 10
        test_iterations: 200  # 足够的测试样本
        concurrent_levels: [1, 5, 10, 15]

    # 并发性能对比
    concurrent_performance:
      models: ["benchmark-model-1", "fast-model"]
      evaluators: ["chat"]
      maxConcurrency: 5
      saveResults: true
      outputPath: "results/concurrent"
      parameters:
        max_examples: 200
        timeout_seconds: 15
        warmup_iterations: 5
        test_iterations: 150
        concurrent_levels: [1, 2, 5, 8, 12]

    # 压力测试模式
    stress_test:
      models: ["benchmark-model-1"]
      evaluators: ["chat"]
      maxConcurrency: 8
      saveResults: true
      outputPath: "results/stress"
      parameters:
        max_examples: 300
        timeout_seconds: 25
        warmup_iterations: 3
        test_iterations: 400
        load_pattern: "burst"  # burst模式压力测试

  settings:
    max_job_concurrency: 8
    response_timeout_seconds: 30
    result_format: "json"
    log_level: "INFO"