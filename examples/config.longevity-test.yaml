# EvalScope 配置文件 - 长期稳定性测试示例
# 适用于评估模型在长期运行中的稳定性表现

evaluations:
  longevity_test:
    evaluationName: "longevity_test"
    evaluatorTypes: ["chat"]
    maxConcurrency: 5
    datasetPath: "datasets/LongConvo/test.json"
    saveResults: true
    resultFormat: "json"
    outputPath: "results/longevity/"
    parameters:
      max_examples: 100
      number: 50
      rounds: 10
      concurrent: 5
      max_workers: 10
      connect_timeout: 60
      read_timeout: 180
      max_retries: 10
      retry_delay: 5000

      # 模型请求参数
      max_tokens: 4096
      temperature: 0.8
      top_p: 0.9
      frequency_penalty: 0.1
      presence_penalty: 0.1

      # 评估指标
      metrics: "latency,throughput,error_rate,staleness"
      include_latency: true
      include_accuracy: true

      # 速率限制
      requests_per_second: 1
      requests_per_minute: 60

      # 测试模式
      debug: false
      verbose: true

      # 长期测试特殊参数
      pause_interval: 30
      pause_duration: 10

# 数据集配置
datasets:
  longconvo_test:
    format: "LongConvo"
    path: "datasets/LongConvo/test.json"
    parameters:
      shuffle: true
      limit: 100
      validate: true
      conversation_length: 20

models:
  gpt35_turbo:
    modelId: "gpt-3.5-turbo"
    modelType: "chat"
    provider: "openai"
    enabled: true
    parameters:
      endpoint: "https://api.openai.com/v1"
      max_tokens: 4096
      temperature: 0.8
      top_p: 0.9
      frequency_penalty: 0.1
      presence_penalty: 0.1
      stream: false
    credentials:
      api_key: "${OPENAI_API_KEY}"

# 系统配置
system:
  log_level: "INFO"
  output_prettify: true
  performance_tracking: true

  # 结果存储配置
  result_storage:
    type: "local"
    path: "results/longevity/"
    format: "json"

  # 指标收集配置
  metrics:
    collection_interval: 60
    retention_days: 90
    export_format: "json"

  # 连接池配置
  connection_pool:
    max_connections: 20
    connection_timeout: 60
    read_timeout: 180
    retry_attempts: 10
    backoff_multiplier: 2.0