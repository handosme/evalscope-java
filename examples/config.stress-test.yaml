# EvalScope 配置文件 - 压力测试示例
# 适用于评估模型在高并发场景下的性能表现

evaluations:
  stress_test:
    evaluationName: "stress_test"
    evaluatorTypes: ["chat"]
    maxConcurrency: 100
    datasetPath: "datasets/CrossWOZ/test.json"
    saveResults: true
    resultFormat: "json"
    outputPath: "results/stress/"
    parameters:
      max_examples: 2000
      number: 100
      rounds: 3
      concurrent: 100
      max_workers: 150
      connect_timeout: 30
      read_timeout: 60
      max_retries: 5
      retry_delay: 1000

      # 模型请求参数
      max_tokens: 512
      temperature: 0.8
      top_p: 0.9
      frequency_penalty: 0.1
      presence_penalty: 0.1

      # 评估指标
      metrics: "latency,throughput,error_rate"
      include_latency: true
      include_accuracy: false

      # 速率限制
      requests_per_second: 10
      requests_per_minute: 600

      # 测试模式
      debug: false
      verbose: true

datasets:
  stress_test_dataset:
    format: "CrossWOZ"
    path: "datasets/CrossWOZ/test.json"
    parameters:
      shuffle: true
      limit: 2000
      validate: true

models:
  gpt35_turbo:
    modelId: "gpt-3.5-turbo"
    modelType: "chat"
    provider: "openai"
    enabled: true
    parameters:
      endpoint: "https://api.openai.com/v1"
      max_tokens: 512
      temperature: 0.8
      top_p: 0.9
      frequency_penalty: 0.1
      presence_penalty: 0.1
      stream: false
    credentials:
      api_key: "${OPENAI_API_KEY}"

  gpt35_turbo_high_temp:
    modelId: "gpt-3.5-turbo-high-temp"
    modelType: "chat"
    provider: "openai"
    enabled: true
    parameters:
      endpoint: "https://api.openai.com/v1"
      max_tokens: 1024
      temperature: 1.2
      top_p: 0.95
      frequency_penalty: 0.2
      presence_penalty: 0.2
      stream: false
    credentials:
      api_key: "${OPENAI_API_KEY}"

# 系统配置
system:
  log_level: "INFO"
  output_prettify: true
  performance_tracking: true

  # 结果存储配置
  result_storage:
    type: "local"
    path: "results/stress/"
    format: "json"

  # 指标收集配置
  metrics:
    collection_interval: 10
    retention_days: 30
    export_format: "json"

  # 连接池配置
  connection_pool:
    max_connections: 200
    connection_timeout: 30
    read_timeout: 60
    retry_attempts: 3
    backoff_multiplier: 2.0