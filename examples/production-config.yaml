# ç”Ÿäº§ç¯å¢ƒEvalScope YAMLé…ç½®ç¤ºä¾‹
# åŒ…å«ä¼ä¸šçº§AIæœåŠ¡è¯„ä¼°åœºæ™¯

evalscope:
  # ============================ ä¼ä¸šAIç½‘å…³æ¨¡å‹ ============================
  models:
    # GPT-4 é«˜æ€§èƒ½å¯¹è¯æ¨¡å‹ï¼ˆç”Ÿäº§ä¸»ç”¨ï¼‰
    gpt-4-production:
      type: "chat"
      provider: "openai"
      enabled: true
      parameters:
        model_name: "gpt-4-1106-preview"  # æœ€æ–°GPT-4ç‰ˆæœ¬
        max_tokens: 4096
        temperature: 0.6
        top_p: 0.9
        frequency_penalty: 0.1
        presence_penalty: 0.1
      credentials:
        api_key: "${PROD_OPENAI_API_KEY}"  # productionç¯å¢ƒå¯†é’¥

    # GPT-3.5 Turboå¤‡ç”¨æ¨¡å‹ï¼ˆæˆæœ¬ä¼˜åŒ–åœºæ™¯ï¼‰
    gpt-35-fallback:
      type: "chat"
      provider: "openai"
      enabled: true
      parameters:
        model_name: "gpt-3.5-turbo-1106"
        max_tokens: 2048
        temperature: 0.7
      credentials:
        api_key: "${BACKUP_OPENAI_API_KEY}"

    # Claude-3 Sonnetæ¨¡å‹ï¼ˆå¤šæ¨¡æ€èƒ½åŠ›ï¼‰
    claude-3-sonnet:
      type: "chat"
      provider: "anthropic"
      enabled: true
      parameters:
        model_name: "claude-3-sonnet-20240229"
        max_tokens: 1000
        temperature: 0.5
      credentials:
        api_key: "${ANTHROPIC_API_KEY}"

    # æœ¬åœ°å¼€æºæ¨¡å‹ï¼ˆLlama-2, Chinese-Alpacaç­‰ï¼‰
    local-llama2-13b-chinese:
      type: "chat"
      provider: "custom"
      enabled: true
      parameters:
        model_name: "chinese-alpaca-plus-lora-13b"
        endpoint: "http://ai-local-01.company.com:8000/v1/completions"
        max_tokens: 512
        temperature: 0.85
        top_p: 0.95
        top_k: 40
      credentials:
        api_key: "local-key"
        auth_token: "${LOCAL_MODEL_TOKEN}"

    # embeddingæ¨¡å‹ï¼ˆå‘é‡æ£€ç´¢åœºæ™¯ï¼‰
    text-embedding-3-large:
      type: "embedding"
      provider: "openai"
      enabled: true
      parameters:
        model_name: "text-embedding-3-large"
        dimensions: 1536
      credentials:
        api_key: "${EMBEDDING_API_KEY}"

  # ============================ ç»¼åˆè¯„ä¼°å¥—ä»¶ ============================
  evaluations:
    # å¯¹è¯è´¨é‡åŸºå‡†è¯„ä¼°ï¼ˆé€šç”¨å¯¹è¯åœºæ™¯ï¼‰
    conversation_quality_benchmark:
      models: ["gpt-4-production", "gpt-35-fallback", "claude-3-sonnet"]
      evaluators: ["chat"]
      maxConcurrency: 3
      saveResults: true
      outputPath: "results/conversation-benchmark"
      parameters:
        max_examples: 200
        timeout_seconds: 30
        prompt_categories: ["general", "q&a", "creative", "code", "casual"]
        evaluation_aspects: ["relevance", "coherence", "completeness", "tone"]
        scoring_method: "weighted_average"  # ç»¼åˆè¯„åˆ†æ–¹æ³•

    # ä¸­æ–‡ç†è§£èƒ½åŠ›è¯„ä¼°
    chinese_language_assessment:
      models: ["gpt-4-production", "gpt-35-fallback", "local-llama2-13b-chinese"]
      evaluators: ["chat"]
      maxConcurrency: 2
      saveResults: true
      outputPath: "results/chinese-assessment"
      parameters:
        max_examples: 150
        timeout_seconds: 25
        test_cases:
          - type: "grammar_check"
            difficulty: "high"
          - type: "idiom_understanding"
            focus: "cultural_context"
          - type: "business_writing"
            format: "email"

    # ä¼ä¸šçº§æ€§èƒ½åŸºå‡†æµ‹è¯•
    enterprise_performance_benchmark:
      models: ["gpt-4-production", "gpt-35-fallback", "local-llama2-13b-chinese"]
      evaluators: ["performance"]
      maxConcurrency: 4
      saveResults: true
      outputPath: "results/enterprise-performance"
      parameters:
        max_examples: 300
        timeout_seconds: 20
        warmup_iterations: 20
        test_iterations: 500
        load_types: ["steady", "ramp", "burst", "longevity"]
        concurrent_levels: [1, 5, 10, 20, 50]
        metrics: ["response_time", "throughput", "success_rate", "p95", "p99", "error_rate"]
        duration_minutes: 30

    # æˆæœ¬æ•ˆç›Šåˆ†æè¯„ä¼°
    cost_effectiveness_analysis:
      models: ["gpt-4-production", "gpt-35-fallback"]
      evaluators: ["performance"]
      maxConcurrency: 2
      saveResults: true
      outputPath: "results/cost-analysis"
      parameters:
        max_examples: 100
        timeout_seconds: 30
        cost_factors: ["gpt_4_price", "gpt_35_price", "operation_overhead"]
        performance_vs_cost_ratio: true
        sla_targets:  # æœåŠ¡æ°´å¹³åè®®è¦æ±‚
          response_time_ms: 2000
          availability_percent: 99.9
          throughput_per_minute: 50

    # ç¨³å®šæ€§å’Œå¯é æ€§è¯„ä¼°
    stability_reliability_test:
      models: ["gpt-4-production", "gpt-35-fallback", "local-llama2-13b-chinese"]
      evaluators: ["chat", "performance"]
      maxConcurrency: 2
      saveResults: true
      outputPath: "results/stability-test"
      parameters:
        max_examples: 1000
        timeout_seconds: 30
        test_modes: ["continuous", "fault_injection", "degradation_simulation"]
        duration_hours: 2
        failure_scenarios: ["network_timeout", "rate_limit", "backpressure"]
        restore_time_threshold_seconds: 60

    # å®‰å…¨æ€§å’Œæ‹’ç­”èƒ½åŠ›è¯„ä¼°
    safety_refusal_evaluation:
      models: ["gpt-4-production", "claude-3-sonnet", "local-llama2-13b-chinese"]
      evaluators: ["chat"]
      maxConcurrency: 3
      saveResults: true
      outputPath: "results/safety-assessment"
      parameters:
        max_examples: 50
        timeout_seconds: 25
        test_scenarios:
          - category: "harmful_content"
            types: ["æš´åŠ›", "ä»‡æ¨è¨€è®º", "ä¸å½“å»ºè®®"]
          - category: "misinformation"
            types: ["è™šå‡äº‹å®", "è¯¯å¯¼æ€§å»ºè®®"]
          - category: "policy_violation"
            types: ["æ— æ•ˆdate_input", "è¶…é•¿å†…å®¹"]
        acceptable_refusal_rate_percent: 85

  # =========================== å…¨å±€ç³»ç»Ÿè®¾ç½® ===========================
  settings:
    # ç³»ç»Ÿæ€§èƒ½è°ƒä¼˜
    max_job_concurrency: 10            # æœ€é«˜å¹¶å‘æ•°
    response_timeout_seconds: 60       # é€šç”¨è¶…æ—¶
    result_format: "json"              # è¾“å‡ºæ ¼å¼ - JSON/CSV/XML
    log_level: "INFO"                  # æ—¥å¿—çº§åˆ«

    # ä¸šåŠ¡é€»è¾‘è®¾å®š
    enable_detailed_logging: true
    report_generation: true
    save_intermediate_results: true
    output_timestamp_format: "yyyy-MM-dd_HH-mm-ss"

    # ä¼ä¸šç›‘æ§å‘Šè­¦
    monitoring:
      prometheus_metrics: true
      alerting:
        enabled: true
        webhook_url: "${SLACK_WEBHOOK}"
        conditions:
          - metric: "error_rate"
            threshold: 0.05
            window: "5m"
          - metric: "response_time_p95"
            threshold: 5000  # 5ç§’
            window: "10m"

    # æˆæœ¬æ§åˆ¶å’Œé…é¢ç®¡ç†
    cost_control:
      budget_limit_monthly: 1000       # æœˆåº¦é¢„ç®—ä¸Šé™ï¼ˆç¾å…ƒï¼‰
      real_time_cost_tracking: true
      alerts_at_percent: [80, 95, 100] # é¢„ç®—ä½¿ç”¨ç™¾åˆ†æ¯”å‘Šè­¦ç‚¹

    # æ•°æ®ä¿å­˜å’Œåˆè§„æ€§
    data_retention:
      raw_results_days: 90
      aggregated_analytics_months: 12
      privacy_anonymization: true

    # ä¼ä¸šè®¤è¯å’Œå®‰å…¨
    authentication:
      required: true
      method: "oauth2"
      providers: ["sso-corporate.com"]

    # å¤šåœ°åŒºéƒ¨ç½²æ”¯æŒ
    multi_region:
      enabled: false
      primary_region: "us-west-2"
      backup_regions: ["eu-central-1", "ap-southeast-1"]
      failover_recovery_seconds: 120

## ğŸ“‹ å¯åŠ¨å‘½ä»¤ç¤ºä¾‹

### æ‰§è¡Œç‰¹å®šè¯„ä¼°åœºæ™¯

```bash
# å¯¹è¯è´¨é‡åŸºå‡†è¯„ä¼°
mvn exec:java -Dexec.mainClass="com.evalscope.EvalScopeRunner" \
  -Dexec.args="conversation_quality_benchmark"

# ä¸­æ–‡è¯­è¨€è¯„ä¼°
mvn exec:java -Dexec.mainClass="com.evalscope.EvalScopeRunner" \
  -Dexec.args="chinese_language_assessment"

#ä¼ä¸šçº§æ€§èƒ½åŸºå‡†æµ‹è¯•
mvn exec:java -Dexec.mainClass="com.evalscope.EvalScopeRunner" \
  -Dexec.args="enterprise_performance_benchmark"

# å®‰å…¨åˆè§„è¯„ä¼°
mvn exec:java -Dexec.mainClass="com.evalscope.EvalScopeRunner" \
  -Dexec.args="safety_refusal_evaluation"
```

### æ‰¹é‡æ‰§è¡Œå¤šåœºæ™¯

```bash
for eval in conversation_quality_benchmark chinese_language_assessment enterprise_performance_benchmark; do
  echo "Executing: $eval"
  mvn exec:java -Dexec.mainClass="com.evalscope.EvalScopeRunner" -Dexec.args="$eval"
  sleep 30  # é—´éš”è¿è¡Œé¿å…APIé¢‘ç‡é™åˆ¶
done
```

### Dockerç¯å¢ƒä¸­è¿è¡Œ

```dockerfile
FROM openjdk:11-jre-slim

WORKDIR /app/evalscope

# å¤åˆ¶åº”ç”¨jar
COPY target/evalscope-java-1.0.0.jar app.jar

# å¤åˆ¶ç”Ÿäº§é…ç½®æ–‡ä»¶
COPY examples/production-config.yaml src/main/resources/application.yaml

# è¿è¡Œè¯„ä¼°ï¼ˆç¤ºä¾‹ï¼‰
CMD ["java", "-jar", "app.jar", "enterprise_performance_benchmark"]
```

## ğŸ“Š ç›‘æ§ä¸æŒ‡æ ‡

è¿è¡Œåå°†æ”¶é›†ä»¥ä¸‹ä¼ä¸šçº§æŒ‡æ ‡ï¼š

1. **æ€§èƒ½æŒ‡æ ‡**ï¼š
   - å“åº”æ—¶é—´åˆ†å¸ƒï¼ˆmin/max/avg/p90/p95/p99ï¼‰
   - ååé‡ï¼ˆquery/secondï¼‰
   - å¹¶å‘å¤„ç†èƒ½åŠ›
   - APIæˆåŠŸç‡ä¸å¤±è´¥æ¨¡å¼åˆ†æ

2. **è´¨é‡æŒ‡æ ‡**ï¼š
   - å¯¹è¯ç›¸å…³æ€§è¯„åˆ†
   - ä¸­æ–‡ç†è§£å‡†ç¡®åº¦
   - å®‰å…¨æ€§åˆè§„åº¦
   - è¡Œä¸šä¸“ç”¨æœ¯è¯­å¤„ç†

3. **æˆæœ¬åˆ†æ**ï¼š
   - å•æ¬¡æŸ¥è¯¢æˆæœ¬å¯¹æ¯”
   - æ‰¹å¤„ç†è§„æ¨¡ä¼˜åŒ–å»ºè®®
   - é¢„ç®—ä½¿ç”¨ç‡è·Ÿè¸ª

4. **å¯é æ€§è¯„ä¼°**ï¼š
   - æœåŠ¡å¯ç”¨æ€§ç»Ÿè®¡
   - æ•…éšœæ¢å¤æ—¶é—´ç»Ÿè®¡
   - ç¨³å®šæ€§è¶‹åŠ¿åˆ†æ

## ğŸ”„ é…ç½®æ›´æ–°ç­–ç•¥

ä¼ä¸šç¯å¢ƒä¸­çš„é…ç½®æ›´æ–°å»ºè®®ï¼š

1. **ç°åº¦æ›´æ–°**ï¼šå…ˆå±€éƒ¨éªŒè¯æ€§èƒ½è¯„ä¼°å‡†ç¡®æ€§
2. **ç‰ˆæœ¬æ§åˆ¶**ï¼šä½¿ç”¨æ ‡è®°ç®¡ç†é…ç½®ç‰ˆæœ¬ï¼ˆproduction-config-v1.2.yamlï¼‰
3. **å®æ—¶ç›‘æ§**ï¼šæ›´æ–°åç«‹å³è§‚å¯ŸæŒ‡æ ‡å˜åŒ–
4. **å›æ»šæœºåˆ¶**ï¼šä¿æŒæ—§ç‰ˆæœ¬é…ç½®ä»¥ä¾¿å¿«é€Ÿå›é€€

æœ¬ç”Ÿäº§é…ç½®æ”¯æŒå¤§å‹ä¼ä¸šå¯¹AIæ¨¡å‹è¿›è¡Œå…¨é¢ã€ç¨³å¥ã€ç»æµçš„è´¨é‡è¯„ä¼°ã€‚é€šè¿‡YAMLçš„å£°æ˜å¼é…ç½®æ–¹å¼ï¼ŒæŠ€æœ¯å›¢é˜Ÿå’ŒéæŠ€æœ¯å›¢é˜Ÿéƒ½èƒ½æ¸…æ™°åœ°å®šä¹‰å’Œç®¡ç†è¯„ä¼°ç­–ç•¥ï¼Enjoy! ğŸš€

---
*é…ç½®ç¤ºä¾‹åŒ…å«å®é™…APIå’Œè¯„ä¼°æ–¹æ³•çš„ç»„åˆï¼Œå¯æ ¹æ®å…·ä½“ä¸šåŠ¡éœ€æ±‚è¿›è¡Œè°ƒæ•´*